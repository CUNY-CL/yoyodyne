# Model parameters similar to those of Wu & Cotterell:
# https://aclanthology.org/P19-1148/
# 
# This is the first-order version that enforces monotonicity.
#
# They don't report a batch size.
class_path: yoyodyne.models.HardAttentionLSTMModel
init_args:
  source_encoder:
    class_path: yoyodyne.models.modules.LSTMEncoder
    init_args:
      dropout: .3
      embedding_size: 200
      hidden_size: 400
  attention_context: 1
  decoder_dropout: .3
  decoder_hidden_size: 400
  embedding_size: 200
  enforce_monotonic: true
  optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: .001
