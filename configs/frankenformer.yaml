# Tuning is probably necessary to figure out sensible values here.
class_path: yoyodyne.models.SoftAttentionLSTMModel
init_args:
  source_encoder:
    class_path: yoyodyne.models.modules.TransformerEncoder
    init_args:
      dropout: ${init_args.decoder_dropout}
      embedding_size: ${init_args.embedding_size}
      hidden_size: ${init_args.decoder_hidden_size}
      layers: 4
  decoder_dropout: .3
  decoder_hidden_size: 100
  embedding_size: 300
  optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: .001
