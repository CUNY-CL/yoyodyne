class_path: yoyodyne.models.AttentiveLSTMModel
init_args:
  source_encoder:
    class_path: yoyodyne.models.modules.TransformerEncoder
    init_args:
      dropout: .2
      embedding_size: 128
      hidden_size: 512
      layers: 4
  decoder_dropout: .2
  decoder_hidden_size: 512
  embedding_size: 128
  label_smoothing: .1
  optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: .01
